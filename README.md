# ML Experiments Playground

This repository is dedicated to exploring various machine learning experiments. It serves as a playground for testing different models, algorithms, and datasets to deepen understanding and foster learning in the field of machine learning.

<br>
<br>

# StyleCARN 
File: [style-carn.ipynb](style-carn.ipynb)

The task involves working with a super-resolution (SR) neural network that should be older than 2018. You will also need a test dataset for SR (e.g., DIV2K, but you can choose another dataset).

## Task Description

1. Evaluate the performance of the chosen SR network on the test dataset.
2. Propose a one-shot learning method to improve the performance of the selected SR network on a specific image. The goal is to enhance the network's output quality for the chosen image without significantly slowing down inference. You are not allowed to use methods that substantially slow down inference, and it is preferable to use style transfer methods.

- You have access to the original source image in the codecs, which is of the highest quality. You can use it to enhance the SR network's performance.
- Any solution that improves SR quality compared to the original network and works on any test images from the chosen dataset is considered positive.

## Results and Images 
- Image illustrating the architecture of the selected SR network.
![Image illustrating the architecture of the selected SR network.](img/arch.png "Image illustrating the architecture of the selected SR network.")

- Image displaying the results of the task.
![Image displaying the results of the task.](img/output.png "Image displaying the results of the task.")



<br>
<br>

# Equalized odds 

File: [equalized_odds.ipynb](equalized_odds.ipynb)

[Equality Of Odds](https://mlu-explain.github.io/equality-of-odds/)

#### Experiment about Equalized odds problem and potential solution

#### Machine Learning models learn to make predictions by looking at data with the help of algorithms, both of which can potentially be biased against different groups of people. Unwanted bias in machine learning can inadvertently harm, and negatively stereotype against underrepresented or (historically and otherwise) disfavored groups. Therefore, it is crucial to evaluate and control data and model predictions not only for general machine learning performance but also for bias.